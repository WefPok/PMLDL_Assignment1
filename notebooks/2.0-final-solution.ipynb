{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Declare a T5 model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading preprocessed Data\n",
    "Here I loaded the csv and created a ToxicDetoxDataset to use further during training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "refined_df = pd.read_csv('../data/interim/refined.csv', delimiter='\\t')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ToxicDetoxDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=32):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        toxic, non_toxic = self.data.iloc[idx][['toxic', 'non_toxic']]\n",
    "        input_text = f\"paraphrase: {toxic}\"\n",
    "        target_text = non_toxic\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            input_text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        targets = self.tokenizer.encode(\n",
    "            target_text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'labels': targets.squeeze()\n",
    "        }\n",
    "\n",
    "# Example of creating DataLoader objects\n",
    "dataset = ToxicDetoxDataset(refined_df, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\", position=0, leave=True)\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=inputs, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': total_loss / (progress_bar.n + 1)}, refresh=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
    "    print(f\"Time: {epoch_mins}m {epoch_secs}s\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualizing cross attention\n",
    "The x-axis represents the input tokens (the sequence fed into the encoder).\n",
    "The y-axis represents a particular token in the output sequence that the model is trying to generate.\n",
    "The colors in the heatmap correspond to the weights of the attention mechanism.\n",
    "If a cell in the heatmap is warm, it means that the output token (y-axis) is strongly attending to that particular input token (x-axis) at the current step in the generation process."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the tokenizer and the model\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('../models/model')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.config.output_attentions = True\n",
    "\n",
    "phrase = \"paraphrase: Shut the fuck up your mouth\"\n",
    "\n",
    "inputs = tokenizer(\n",
    "    phrase,\n",
    "    return_tensors=\"pt\",\n",
    ").to(device)\n",
    "\n",
    "# Generate the output and ensure attention is returned\n",
    "output = model.generate(**inputs, return_dict_in_generate=True, output_attentions=True)\n",
    "\n",
    "# Get the encoder and decoder texts\n",
    "encoder_text = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "decoded_ids = output.sequences[0]\n",
    "decoder_text = tokenizer.convert_ids_to_tokens(decoded_ids, skip_special_tokens=True)\n",
    "\n",
    "# Extract cross-attention weights (assuming you are visualizing the first layer's attention)\n",
    "layer = 0\n",
    " # Index for the first token. You can iterate over all tokens if needed\n",
    "\n",
    "# Extract the attention weights for the first layer, averaging across all heads\n",
    "cross_attention = output.cross_attentions[layer][0].mean(dim=0).detach().cpu().numpy()\n",
    "\n",
    "# Reshape the cross_attention to remove any additional dimensions\n",
    "cross_attention = cross_attention.squeeze()\n",
    "\n",
    "# Ensure it's 2D\n",
    "if cross_attention.ndim == 1:\n",
    "    cross_attention = cross_attention[None, :]\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "ax = sns.heatmap(cross_attention, annot=True, cmap='viridis', xticklabels=encoder_text, yticklabels=decoder_text, fmt=\".2f\")\n",
    "plt.xlabel('Input Sequence')\n",
    "plt.ylabel('Output Sequence')\n",
    "plt.title(f'Cross-Attention Weights for the Tokens of Output')\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize=10, rotation=90)\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize=10)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_save_path = \"../models/model/\"\n",
    "model.save_pretrained(model_save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
